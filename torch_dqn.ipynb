{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_dqn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d3sm0/torch_dqn/blob/master/torch_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "320Z1BXmncPF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8uJ8FZvwnkTQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhW2HUYPo354",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def conv2d_size_out(size, kernel_size=5, stride=2):\n",
        "    return (size - (kernel_size - 1) - 1) // stride + 1\n",
        "\n",
        "\n",
        "class QNetwork(torch.nn.Module):\n",
        "    def __init__(self, obs_shape, act_shape):\n",
        "        super(QNetwork, self).__init__()\n",
        "        # self.conv_1 = torch.nn.Conv1d(in_channels=c, out_channels=16, kernel_size=5, stride=2, padding=0)\n",
        "        # self.conv_2 = torch.nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=0)\n",
        "        self.fc_0 = torch.nn.Linear(obs_shape, 64)\n",
        "        self.fc_1 = torch.nn.Linear(64, 64)\n",
        "        # conv_w = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
        "        # conv_h = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
        "\n",
        "        # out_shape = conv_w * conv_h * 32\n",
        "        self.out = torch.nn.Linear(64, act_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view((x.size(0), -1))\n",
        "        x = torch.nn.functional.relu(self.fc_0(x))\n",
        "        x = torch.nn.functional.relu(self.fc_1(x))\n",
        "        x = self.out(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZ78Dq0qo-Ox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "from collections import namedtuple\n",
        "import random\n",
        "\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward', 'done'))\n",
        "\n",
        "# courtesy of the torch tutorial <3\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "\n",
        "\n",
        "class Memory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qdz60hHvpCVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LinearSchedule(object):\n",
        "    def __init__(self, schedule_timesteps, final_p, initial_p=1.0):\n",
        "        \"\"\"Linear interpolation between initial_p and final_p over\n",
        "        schedule_timesteps. After this many timesteps pass final_p is\n",
        "        returned.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        schedule_timesteps: int\n",
        "            Number of timesteps for which to linearly anneal initial_p\n",
        "            to final_p\n",
        "        initial_p: float\n",
        "            initial output value\n",
        "        final_p: float\n",
        "            final output value\n",
        "        \"\"\"\n",
        "        self.schedule_timesteps = schedule_timesteps\n",
        "        self.final_p = final_p\n",
        "        self.initial_p = initial_p\n",
        "        self.p = self.initial_p\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.p\n",
        "\n",
        "    def reset(self):\n",
        "        self.p = self.initial_p\n",
        "\n",
        "    def update(self, t):\n",
        "        \"\"\"See Schedule.value\"\"\"\n",
        "        if self.p > self.final_p:\n",
        "            fraction = min(float(t) / self.schedule_timesteps, 1.0)\n",
        "            self.p = self.initial_p + fraction * (self.final_p - self.initial_p)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-2gTk3UpGjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7ea069c9-91cb-426e-d2f3-a9a5d02c9d0c"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "# env = ImgObsWrapper(env)\n",
        "#path = args.base_path + args.env\n",
        "#os.makedirs(path, exist_ok=True)\n",
        "obs_shape = np.prod(env.observation_space.shape).astype(int)\n",
        "act_shape = env.action_space.n\n",
        "\n",
        "q = QNetwork(obs_shape, act_shape)\n",
        "q_target = QNetwork(obs_shape, act_shape)\n",
        "opt = optim.Adam(lr=1e-3, params=q.parameters())\n",
        "memory = Memory(capacity=int(1e4))\n",
        "scheduler = LinearSchedule(schedule_timesteps=int(1e5 * 0.1), final_p=0.01)\n",
        "\n",
        "from collections import deque\n",
        "avg_rw = deque(maxlen=40)\n",
        "avg_len = deque(maxlen=40)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "UmuAfO0nph8G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OZYfHc1_pMWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    def get_action(s, t):\n",
        "\n",
        "        s = torch.Tensor(s[None, :])\n",
        "        _q = q(s)\n",
        "        if np.random.sample() > scheduler.value:\n",
        "            best_action = np.argmax(_q.detach(), axis=-1).item()\n",
        "        else:\n",
        "            best_action = np.random.randint(0, act_shape)\n",
        "            scheduler.update(t)\n",
        "        return best_action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSoa4HXtpPaL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOxnjCGRpWcu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " def train(batch, gamma = .99):\n",
        "        batch = Transition(*zip(*batch))\n",
        "        s = torch.Tensor(batch.state)\n",
        "        a = torch.Tensor(one_hot(np.array(batch.action), num_classes=act_shape))\n",
        "        r = torch.Tensor(batch.reward)\n",
        "        d = torch.Tensor(batch.done)\n",
        "        s1 = torch.Tensor(batch.next_state)\n",
        "\n",
        "        value = (q(s) * a).sum(dim=-1)\n",
        "        next_value = r + gamma* (1. - d) * torch.max(q_target(s1), dim=-1)[0]\n",
        "        loss = (.5 * (next_value - value) ** 2).mean()\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZfUdA6vkptze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "ca31155a-3992-4d31-8f96-e1b7191bfd81"
      },
      "cell_type": "code",
      "source": [
        " state = env.reset()\n",
        "\n",
        "q_target.load_state_dict(q.state_dict())\n",
        "\n",
        "ep_rw = 0\n",
        "ep_len = 0\n",
        "ep = 0\n",
        "for t in range(int(1e5)):\n",
        "  action = get_action(state, t)\n",
        "  next_state, reward, done, _ = env.step(action)\n",
        "  memory.push(state, action, next_state, reward, done)\n",
        "  ep_rw += reward\n",
        "  ep_len += 1\n",
        "\n",
        "  state = next_state.copy()\n",
        "  if done:\n",
        "    ep += 1\n",
        "    avg_rw.append(ep_rw)\n",
        "    avg_len.append(ep_len)\n",
        "    ep_rw = 0\n",
        "    ep_len = 0\n",
        "    state = env.reset()\n",
        "\n",
        "  if t % 4 == 0 and len(memory) > 64:\n",
        "    batch = memory.sample(batch_size=64)\n",
        "    train(batch)\n",
        "\n",
        "  if t % int(1e4) == 0:\n",
        "    q_target.load_state_dict(q.state_dict())\n",
        "    print(f't:{t}\\tep:{ep}\\tavg_rw:{np.mean(avg_rw)}\\tavg_len:{np.mean(avg_len)}\\teps:{scheduler.value}')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t:0\tep:0\tavg_rw:12.666666666666666\tavg_len:12.666666666666666\teps:1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4d5d5f4d4f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m    \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m    \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-a1061f9ab9e0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batch, gamma)\u001b[0m\n\u001b[1;32m     12\u001b[0m        \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m        \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m        \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GhqnkrofpxPD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}